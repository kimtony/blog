## ai

### 数据预处理
* Embedding 是将高维数据（如文本、图像或音频）转换为固定维度的低维向量的过程。这些向量保留了原始数据的语义信息，便于进行数学运算和比较。
* 是一个过程或技术，用于将数据转换为向量表示，生成的向量可以存储在 VectorDB 中
* Embedding 是 transformer 模型的一部分，但不仅限于 transformer。其他模型（如 Word2Vec、GloVe）也可以生成嵌入向量

### 数据存储
* VectorDB 是一种存储和检索向量数据的数据库。向量数据库：本地内存HNSWLib，分布式Milvus

### LLM模型 
* 1. 文本生成
* 2. 机器翻译
* 3. 问答系统
* 4. 文本摘要
* 5. 情感分析
* 6. 文本分类
* 7. 个性化推荐
 
## 大模型分析流程
### 1. 文本输入处理
首先，输入的文本数据需要被处理成模型可以理解的形式。具体包括：
* 分词（Tokenization）：将文本分解为单词或子词（token）。
* 添加特殊标记：如句子的起始（<start>）和结束（<end>）标记。
* 词嵌入（Word Embeddings）：将分词后的token映射到高维向量空间中。这一步可以使用预训练的嵌入模型（如 Word2Vec、GloVe）或模型自身的嵌入层。
### 2. 位置编码（Positional Encoding）
* 在 transformer 模型中，由于没有循环或卷积操作，需要位置编码来保留输入序列中各个 token 的位置信息。位置编码可以是固定的（如正弦和余弦函数）或可训练的。
### 3. 自注意力机制（Self-Attention Mechanism）
Transformer 模型中的自注意力机制允许模型在计算每个 token 表示时，考虑输入序列中所有其他 token。具体包括：
* 计算查询、键和值（Query, Key, Value）：从输入嵌入生成。
* 计算注意力权重：使用点积注意力机制，通过对查询和键进行点积运算，再通过 softmax 函数归一化。
* 加权求和：对值进行加权求和，生成新的表示。
### 4. 编码器和解码器（Encoder and Decoder）
对于 seq2seq 任务（如翻译），transformer 包含编码器和解码器：
* 编码器（Encoder）：处理输入序列，生成上下文表示。
* 解码器（Decoder）：根据编码器的输出和先前生成的 token，生成输出序列。
### 5. 预测输出
* 对于文本生成任务，解码器逐步生成输出 token，每一步都依赖于之前生成的 token 和编码器的上下文表示。
### 6. 输出后处理
* 模型生成的 token 序列需要经过后处理，具体包括：
去除特殊标记：如起始和结束标记。
合并 token：将子词合并成完整的单词或句子。

```
大型语言模型通过分词、嵌入、位置编码、自注意力机制和 transformer 架构等步骤来分析和处理输入文本。
最终，模型根据任务需求生成预测输出。不同任务（如文本生成、情感分析、问答系统等）可能在具体实现上有所不同，但基本原理相似。
```
